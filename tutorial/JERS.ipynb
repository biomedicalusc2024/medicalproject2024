{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JERS (Joint Embedding for Radiology and Surgery) Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the JERS modules in the medical project for brain imaging analysis with joint embedding techniques.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The JERS module provides functionality for:\n",
    "1. **Brain Image Processing**: Specialized processing for brain imaging data\n",
    "2. **Joint Embedding**: Links radiology and surgical information through shared representations\n",
    "3. **BraTS Integration**: Works with BraTS brain tumor segmentation dataset\n",
    "4. **Pre-trained Models**: Ready-to-use model weights and templates\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Environment Check](#setup)\n",
    "2. [BraTS Dataset Loading](#brats-loading)\n",
    "3. [JERS Preprocessing](#jers-preprocessing)\n",
    "4. [Model Usage](#model-usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment Check {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjl20001104/anaconda3/envs/hugging-health/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /home/tjl20001104/workspace/Projects/USC/biobank/hugging-health/medicalproject2024/tutorial\n",
      "Project root: /home/tjl20001104/workspace/Projects/USC/biobank/hugging-health\n",
      "JERS path: /home/tjl20001104/workspace/Projects/USC/biobank/hugging-health/medicalproject2024/preprocess/JERS\n",
      "JERS path exists: True\n",
      "JERS modules found!\n",
      "\n",
      "Available files:\n",
      "  Exists inference.py\n",
      "  Exists model.py\n",
      "  Exists utils.py\n",
      "  Exists checkpoints/\n",
      "\n",
      "Python path updated with: /home/tjl20001104/workspace/Projects/USC/biobank/hugging-health\n"
     ]
    }
   ],
   "source": [
    "# Check if the JERS modules exist and are accessible\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the current notebook directory\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent.parent  # Assuming notebook is in tutorial/\n",
    "jers_path = project_root / \"medicalproject2024\" / \"preprocess\" / \"JERS\"\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"JERS path: {jers_path}\")\n",
    "print(f\"JERS path exists: {jers_path.exists()}\")\n",
    "\n",
    "if jers_path.exists():\n",
    "    print(\"JERS modules found!\")\n",
    "    \n",
    "    # Check available files\n",
    "    files = {\n",
    "        \"inference.py\": jers_path / \"inference.py\",\n",
    "        \"model.py\": jers_path / \"model.py\", \n",
    "        \"utils.py\": jers_path / \"utils.py\",\n",
    "        \"checkpoints/\": jers_path / \"checkpoints\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAvailable files:\")\n",
    "    for file_name, file_path in files.items():\n",
    "        status = \"Exists\" if file_path.exists() else \"Not Found\"\n",
    "        print(f\"  {status} {file_name}\")\n",
    "        \n",
    "else:\n",
    "    print(\"JERS modules not found!\")\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"\\nPython path updated with: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing JERS Module Imports:\n",
      "----------------------------------------\n",
      "JERS Model     : Successfully imported\n",
      "JERS Main      : Successfully imported\n",
      "BraTS Loader   : Successfully imported\n"
     ]
    }
   ],
   "source": [
    "# Test importing JERS modules\n",
    "def test_jers_imports():\n",
    "    \"\"\"Test importing JERS modules\"\"\"\n",
    "    print(\"Testing JERS Module Imports:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    modules_to_test = [\n",
    "        (\"medicalproject2024.preprocess.JERS.model\", \"JERS Model\"),\n",
    "        (\"medicalproject2024.preprocess.JERS\", \"JERS Main\"),\n",
    "        (\"medicalproject2024.dataLoader.segmentation.BraTS\", \"BraTS Loader\"),\n",
    "    ]\n",
    "    \n",
    "    import_results = {}\n",
    "    \n",
    "    for module_path, module_name in modules_to_test:\n",
    "        try:\n",
    "            __import__(module_path, fromlist=[''])\n",
    "            import_results[module_name] = True\n",
    "            print(f\"{module_name:15}: Successfully imported\")\n",
    "        except ImportError as e:\n",
    "            import_results[module_name] = False\n",
    "            print(f\"{module_name:15}: Import failed - {str(e)[:50]}...\")\n",
    "        except Exception as e:\n",
    "            import_results[module_name] = False\n",
    "            print(f\"{module_name:15}: Warning - {str(e)[:50]}...\")\n",
    "    \n",
    "    return import_results\n",
    "\n",
    "# Run import tests\n",
    "import_results = test_jers_imports()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BraTS Dataset Loading {#brats-loading}\n",
    "\n",
    "Load BraTS dataset for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BraTS Dataset:\n",
      "==============================\n",
      "Successfully imported BraTS loader\n",
      "\n",
      "Loading BraTS data...\n",
      "BraTS dataset loaded: 1251 samples\n",
      "   Columns: ['raw_img_path', 'dataset_name']\n",
      "\n",
      "Using first 3 samples for processing:\n",
      "   Sample 1: BraTS2021_00402_t1.nii.gz\n",
      "   Sample 2: BraTS2021_01003_t1.nii.gz\n",
      "   Sample 3: BraTS2021_00757_t1.nii.gz\n"
     ]
    }
   ],
   "source": [
    "def load_brats_dataset():\n",
    "    \"\"\"Load BraTS dataset as in test_jers.py\"\"\"\n",
    "    print(\"Loading BraTS Dataset:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        from medicalproject2024.dataLoader.segmentation.BraTS import getBraTS\n",
    "        print(\"Successfully imported BraTS loader\")\n",
    "        \n",
    "        # Load BraTS data\n",
    "        print(\"\\nLoading BraTS data...\")\n",
    "        brats_data = getBraTS(\"data\")\n",
    "        \n",
    "        if brats_data:\n",
    "            dataset = pd.DataFrame(brats_data)\n",
    "            dataset[\"dataset_name\"] = \"BraTS\"\n",
    "            dataset = dataset.rename(columns={\"t1\": \"raw_img_path\"})\n",
    "            dataset = dataset[[\"raw_img_path\", \"dataset_name\"]]\n",
    "            \n",
    "            print(f\"BraTS dataset loaded: {len(dataset)} samples\")\n",
    "            print(f\"   Columns: {list(dataset.columns)}\")\n",
    "            \n",
    "            dataset = dataset.iloc[:3]\n",
    "            print(f\"\\nUsing first 3 samples for processing:\")\n",
    "            for i, row in dataset.iterrows():\n",
    "                print(f\"   Sample {i+1}: {Path(row['raw_img_path']).name}\")\n",
    "            \n",
    "            return dataset\n",
    "        else:\n",
    "            print(\"No BraTS data returned\")\n",
    "            return None\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"Failed to import BraTS loader: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading BraTS data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load BraTS dataset\n",
    "if import_results.get(\"BraTS Loader\", False):\n",
    "    brats_dataset = load_brats_dataset()\n",
    "else:\n",
    "    print(\"Skipping BraTS loading due to import failure\")\n",
    "    brats_dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. JERS Preprocessing {#jers-preprocessing}\n",
    "\n",
    "Run JERS preprocessing exactly as in test_jers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running JERS Preprocessing:\n",
      "========================================\n",
      "Successfully imported JERS_preprocess\n",
      "\n",
      "Processing 2 samples...\n",
      "   Input: BraTS dataset with 2 samples\n",
      "   Output directory: data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2/2 [00:09<00:00,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JERS preprocessing completed!\n",
      "   Result type: <class 'dict'>\n",
      "   Result keys: ['BraTS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run JERS preprocessing (exactly as in test_jers.py)\n",
    "def run_jers_preprocessing(dataset):\n",
    "    \"\"\"Run JERS preprocessing as in test_jers.py\"\"\"\n",
    "    if dataset is None or len(dataset) == 0:\n",
    "        print(\"No dataset available for preprocessing\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Running JERS Preprocessing:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        from medicalproject2024.preprocess.JERS import JERS_preprocess\n",
    "        print(\"Successfully imported JERS_preprocess\")\n",
    "        print(f\"\\nProcessing {len(dataset)} samples...\")\n",
    "        data_dict = {\"BraTS\": dataset}\n",
    "        output_dir = \"data\"\n",
    "        \n",
    "        print(f\"   Input: BraTS dataset with {len(dataset)} samples\")\n",
    "        print(f\"   Output directory: {output_dir}\")\n",
    "        res = JERS_preprocess(data_dict, output_dir)\n",
    "        \n",
    "        print(\"JERS preprocessing completed!\")\n",
    "        print(f\"   Result type: {type(res)}\")\n",
    "        \n",
    "        if hasattr(res, 'shape'):\n",
    "            print(f\"   Result shape: {res.shape}\")\n",
    "        elif isinstance(res, (list, tuple)):\n",
    "            print(f\"   Result length: {len(res)}\")\n",
    "        elif isinstance(res, dict):\n",
    "            print(f\"   Result keys: {list(res.keys())}\")\n",
    "        \n",
    "        return res\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"Failed to import JERS_preprocess: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Preprocessing failed: {e}\")\n",
    "        print(\"   This might be due to missing input files or insufficient resources\")\n",
    "        return None\n",
    "\n",
    "# Run preprocessing\n",
    "if brats_dataset is not None and import_results.get(\"JERS Main\", False):\n",
    "    preprocessing_result = run_jers_preprocessing(brats_dataset)\n",
    "else:\n",
    "    print(\"Skipping preprocessing due to missing dataset or JERS module\")\n",
    "    preprocessing_result = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Usage {#model-usage}\n",
    "\n",
    "Demonstrate JERS model creation and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test JERS model (as in test_jers.py)\n",
    "def create_jers_model():\n",
    "    \"\"\"Create JERS model with parameters from test_jers.py\"\"\"\n",
    "    print(\"Creating JERS Model:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        from medicalproject2024.preprocess.JERS.model import JERS\n",
    "        print(\"Successfully imported JERS model\")\n",
    "        print(\"\\nCreating model with parameters (96, 5, 5, 10)...\")\n",
    "        model = JERS(96, 5, 5, 10)\n",
    "        \n",
    "        # Model info\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"JERS model created successfully\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        \n",
    "        # Check for pre-trained weights\n",
    "        model_weights_path = jers_path / \"checkpoints\" / \"model_state.pt\"\n",
    "        if model_weights_path.exists():\n",
    "            print(f\"\\nPre-trained weights found: {model_weights_path}\")\n",
    "            try:\n",
    "                state_dict = torch.load(model_weights_path, map_location='cpu')\n",
    "                model.load_state_dict(state_dict)\n",
    "                print(\"Pre-trained weights loaded successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load weights: {e}\")\n",
    "        else:\n",
    "            print(\"\\nNo pre-trained weights found\")\n",
    "            print(\"To save model state: torch.save(model.state_dict(), 'model_state.pt')\")\n",
    "        \n",
    "        model.eval()\n",
    "        return model\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"Failed to import JERS model: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create JERS model\n",
    "if import_results.get(\"JERS Model\", False):\n",
    "    jers_model = create_jers_model()\n",
    "else:\n",
    "    print(\"Skipping model creation due to import failure\")\n",
    "    jers_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model with dummy data\n",
    "def test_model_inference(model):\n",
    "    \"\"\"Test model inference with dummy data\"\"\"\n",
    "    if model is None:\n",
    "        print(\"No model available for testing\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nTesting Model Inference:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # Create dummy input (based on template size 96x96x96)\n",
    "        dummy_input = torch.randn(1, 1, 96, 96, 96)\n",
    "        print(f\"Testing with input shape: {dummy_input.shape}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(dummy_input)\n",
    "            \n",
    "        print(\"Model inference successful!\")\n",
    "        print(f\"   Output shape: {output.shape if hasattr(output, 'shape') else type(output)}\")\n",
    "        \n",
    "        if hasattr(output, 'shape'):\n",
    "            print(f\"   Output range: [{output.min():.4f}, {output.max():.4f}]\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Inference failed: {e}\")\n",
    "        print(\"   This might be due to incorrect input dimensions\")\n",
    "\n",
    "# Test model inference\n",
    "if jers_model is not None:\n",
    "    test_model_inference(jers_model)\n",
    "else:\n",
    "    print(\"Skipping inference test due to model creation failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the JERS workflow following the exact structure from `test_jers.py`:\n",
    "\n",
    "### Key Steps:\n",
    "1. **Environment Setup**: Import required modules and check availability\n",
    "2. **BraTS Dataset Loading**: Load and prepare BraTS brain tumor dataset\n",
    "3. **JERS Preprocessing**: Process the dataset using `JERS_preprocess`\n",
    "4. **Model Creation**: Create JERS model with parameters (96, 5, 5, 10)\n",
    "\n",
    "### Files Structure:\n",
    "- **model.py**: Contains JERS neural network architecture\n",
    "- **inference.py**: Inference pipeline for processing\n",
    "- **utils.py**: Utility functions\n",
    "- **checkpoints/**: Pre-trained weights and templates\n",
    "  - `model_state.pt`: Model weights\n",
    "  - `template_img_orig_96.npy`: Brain template (96x96x96)\n",
    "  - `template_img_gm_mask_orig_96.npy`: Gray matter mask\n",
    "\n",
    "### Usage Notes:\n",
    "- The workflow processes 3 BraTS samples by default\n",
    "- Output is saved to `data/` directory\n",
    "- Model uses 96x96x96 input dimensions\n",
    "- Pre-trained weights are automatically loaded if available\n",
    "\n",
    "### Next Steps:\n",
    "- Use your own brain imaging data with the preprocessing pipeline\n",
    "- Experiment with different model parameters\n",
    "- Explore the joint embedding capabilities for radiology-surgery applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
