{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroimaging Preprocessing Tutorial\n",
    "\n",
    "This tutorial demonstrates neuroimaging preprocessing using **DeepPrep**, a computationally efficient, scalable, and robust preprocessing pipeline empowered by deep learning and workflow managers.\n",
    "\n",
    "**Official Documentation**: https://deepprep.readthedocs.io/en/latest/installation.html\n",
    "\n",
    "### Why DeepPrep?\n",
    "\n",
    "- **Fast**: 11x faster than fMRIPrep\n",
    "- **Deep Learning-Powered**: Uses state-of-the-art deep learning algorithms:\n",
    "  - **FastSurfer**: Brain tissue segmentation\n",
    "  - **FastCSR**: Cortical surface reconstruction\n",
    "  - **SUGAR**: Cortical surface registration\n",
    "  - **SynthMorph**: Volumetric spatial normalization\n",
    "- **Highly Scalable**: Supports local workstations, HPC clusters, and cloud computing environments\n",
    "- **Robust**: 100% success rate in processing clinical samples\n",
    "\n",
    "### Supported Data Types\n",
    "\n",
    "- Anatomical MRI (T1w, T2w, FLAIR)\n",
    "- Functional MRI (BOLD)\n",
    "- CIFTI format output\n",
    "\n",
    "### Citation\n",
    "\n",
    "If you use DeepPrep in your research, please cite:\n",
    "\n",
    "Ren, J.*, An, N.*, Lin, C., et al. (2025). DeepPrep: an accelerated, scalable and robust pipeline for neuroimaging preprocessing empowered by deep learning. *Nature Methods*. https://doi.org/10.1038/s41592-025-02599-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Installation\n",
    "\n",
    "This tutorial requires two environments:\n",
    "\n",
    "1. **Python Environment** (for this notebook)\n",
    "   - Used for data format conversion (ADNI → BIDS)\n",
    "   - Required packages: `pydicom`, `nibabel`, `numpy`\n",
    "\n",
    "2. **DeepPrep Docker** (for brain imaging preprocessing)\n",
    "   - The main preprocessing pipeline\n",
    "   - Runs independently in a container\n",
    "   \n",
    "Let's set up both environments step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 System Requirements\n",
    "\n",
    "Before installing DeepPrep, ensure your system meets the following requirements:\n",
    "\n",
    "#### Hardware Requirements\n",
    "\n",
    "| Component | Minimum | Recommended |\n",
    "|-----------|---------|-------------|\n",
    "| CPU | 4 cores | 8+ cores |\n",
    "| RAM | 12GB + Swap space | 32GB+ |\n",
    "| Disk Space | 20GB | 100GB+ |\n",
    "| GPU (Optional) | 10GB+ VRAM | NVIDIA GPU with CUDA 11.8+ |\n",
    "\n",
    "#### Software Requirements\n",
    "\n",
    "- **Operating System**: Ubuntu 20.04 or newer (Linux-based systems)\n",
    "- **Container Platform**: Docker or Singularity\n",
    "- **GPU Drivers** (if using GPU): NVIDIA Driver 520.61.05+ and CUDA 11.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Check Your System\n",
    "\n",
    "Let's verify your system meets the requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Docker installation\n",
    "!docker --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available disk space\n",
    "!df -h /var/lib/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check home directory space\n",
    "!df -h ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CPU information\n",
    "!lscpu | grep -E \"^CPU\\(s\\)|Model name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available RAM\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU (if available)\n",
    "!nvidia-smi 2>/dev/null || echo \"No NVIDIA GPU detected (CPU-only mode will be used)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Install Docker (If Not Already Installed)\n",
    "\n",
    "If Docker is not installed, you can install it using the following commands in your terminal:\n",
    "\n",
    "```bash\n",
    "# Update package index\n",
    "sudo apt-get update\n",
    "\n",
    "# Install required packages\n",
    "sudo apt-get install -y \\\n",
    "    ca-certificates \\\n",
    "    curl \\\n",
    "    gnupg \\\n",
    "    lsb-release\n",
    "\n",
    "# Add Docker's official GPG key\n",
    "sudo mkdir -p /etc/apt/keyrings\n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n",
    "\n",
    "# Set up the repository\n",
    "echo \\\n",
    "  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n",
    "  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "\n",
    "# Install Docker Engine\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n",
    "\n",
    "# Add your user to the docker group (to run Docker without sudo)\n",
    "sudo usermod -aG docker $USER\n",
    "\n",
    "# Apply the new group membership (or logout and login)\n",
    "newgrp docker\n",
    "```\n",
    "\n",
    "**Note**: After adding yourself to the docker group, you may need to log out and log back in for the changes to take effect.\n",
    "\n",
    "Let's check if Docker is already installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Docker is installed\n",
    "!which docker && echo \"✓ Docker is already installed\" || echo \"✗ Docker not found - please install using the commands above\"\n",
    "\n",
    "# Check Docker service status\n",
    "!sudo systemctl status docker --no-pager 2>/dev/null | grep \"Active:\" || echo \"Note: Docker service status check requires sudo privileges\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Pull DeepPrep Docker Image\n",
    "\n",
    "DeepPrep is distributed as a Docker image. The latest version is **pbfslab/deepprep:25.1.0**.\n",
    "\n",
    "**Important Notes**:\n",
    "- The Docker image is approximately **10-15GB** in size\n",
    "- Download time depends on your internet connection\n",
    "- Make sure you have sufficient disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the DeepPrep Docker image\n",
    "# If you're in the docker group, run:\n",
    "!docker pull pbfslab/deepprep:25.1.0\n",
    "\n",
    "# If you need sudo privileges, run this in terminal:\n",
    "# sudo docker pull pbfslab/deepprep:25.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Verify Installation\n",
    "\n",
    "Let's verify that the DeepPrep image was successfully downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List DeepPrep Docker images\n",
    "!docker images pbfslab/deepprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see output similar to:\n",
    "\n",
    "```\n",
    "REPOSITORY           TAG       IMAGE ID       CREATED        SIZE\n",
    "pbfslab/deepprep     25.1.0    xxxxxxxxxxxx   x weeks ago    xx.xGB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Preparation\n",
    "\n",
    "Before running DeepPrep, you need to prepare the following:\n",
    "\n",
    "#### 1.6.1 FreeSurfer License\n",
    "\n",
    "DeepPrep requires a **FreeSurfer license** to run. This is a free license that you can obtain from the FreeSurfer website.\n",
    "\n",
    "**Steps to obtain FreeSurfer license:**\n",
    "\n",
    "1. Visit the FreeSurfer registration page: https://surfer.nmr.mgh.harvard.edu/registration.html\n",
    "2. Fill out the registration form with your information\n",
    "3. You will receive an email with the `license.txt` file\n",
    "4. Save the license file to a known location on your computer\n",
    "\n",
    "**Recommended location**: `$HOME/freesurfer/license.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directory for FreeSurfer license\n",
    "freesurfer_dir = os.path.expanduser(\"~/freesurfer\")\n",
    "os.makedirs(freesurfer_dir, exist_ok=True)\n",
    "\n",
    "print(f\"FreeSurfer directory created at: {freesurfer_dir}\")\n",
    "print(f\"Please save your license.txt file to: {freesurfer_dir}/license.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if FreeSurfer license exists\n",
    "import os\n",
    "\n",
    "license_path = os.path.expanduser(\"~/freesurfer/license.txt\")\n",
    "\n",
    "if os.path.exists(license_path):\n",
    "    print(f\"✓ FreeSurfer license found at: {license_path}\")\n",
    "    print(\"\\nLicense content:\")\n",
    "    with open(license_path, 'r') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(f\"✗ FreeSurfer license NOT found at: {license_path}\")\n",
    "    print(\"\\nPlease:\")\n",
    "    print(\"1. Obtain a license from: https://surfer.nmr.mgh.harvard.edu/registration.html\")\n",
    "    print(f\"2. Save it to: {license_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2 Convert ADNI Data to BIDS Format\n",
    "\n",
    "DeepPrep requires input data in **BIDS (Brain Imaging Data Structure)** format. Our dataset is from ADNI and contains three modalities:\n",
    "- **MRI** (T1-weighted structural images)\n",
    "- **AV45 PET** (Amyloid PET imaging)\n",
    "- **FDG PET** (Glucose metabolism PET imaging)\n",
    "\n",
    "**Current ADNI data structure:**\n",
    "```\n",
    "data/002_S_0295/\n",
    "├── MPR__GradWarp__B1_Correction__N3/              # MRI T1w\n",
    "│   └── 2009-05-22_07_00_57.0/\n",
    "│       └── I150176/*.nii\n",
    "├── AV45_Coreg,_Avg,_Standardized_Image_and_Voxel_Size/  # AV45 PET\n",
    "│   └── 2011-06-10_16_22_23.0/\n",
    "│       └── I240520/*.dcm\n",
    "└── Coreg,_Avg,_Standardized_Image_and_Voxel_Size/       # FDG PET\n",
    "    └── 2011-06-09_08_23_48.0/\n",
    "        └── I240517/*.dcm\n",
    "```\n",
    "\n",
    "**Target BIDS structure:**\n",
    "```\n",
    "bids_dataset/\n",
    "├── dataset_description.json\n",
    "├── participants.tsv\n",
    "└── sub-0020295/\n",
    "    ├── anat/\n",
    "    │   └── sub-0020295_T1w.nii.gz\n",
    "    └── pet/\n",
    "        ├── sub-0020295_trc-AV45_pet.nii.gz\n",
    "        ├── sub-0020295_trc-AV45_pet.json\n",
    "        ├── sub-0020295_trc-FDG_pet.nii.gz\n",
    "        └── sub-0020295_trc-FDG_pet.json\n",
    "```\n",
    "\n",
    "We'll write a Python script to perform this conversion automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required pixel data handlers for pydicom\n",
    "# Run this cell if you encounter \"ImportError: NumPy is required when converting pixel data to an ndarray\"\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q pillow pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg python-gdcm\n",
    "\n",
    "# Test the installation\n",
    "try:\n",
    "    import pydicom\n",
    "    import numpy as np\n",
    "    print(\"✓ pydicom and numpy imported successfully\")\n",
    "    \n",
    "    # Test pixel data handler\n",
    "    import glob\n",
    "    dcm_files = glob.glob('data/002_S_0295/*/2011*/I*/*.dcm')\n",
    "    if dcm_files:\n",
    "        ds = pydicom.dcmread(dcm_files[0])\n",
    "        pixel_data = ds.pixel_array\n",
    "        print(f\"✓ Pixel data access working - shape: {pixel_data.shape}\")\n",
    "    else:\n",
    "        print(\"⚠ No DICOM files found for testing\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "    print(\"\\nPlease restart the kernel after running this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Import required libraries with proper error handling\n",
    "try:\n",
    "    import pydicom\n",
    "    from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    print(\"✓ All required libraries imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import error: {e}\")\n",
    "    print(\"Please install required packages:\")\n",
    "    print(\"  pip install pydicom numpy nibabel pillow\")\n",
    "    raise\n",
    "\n",
    "def convert_adni_to_bids(adni_data_dir, bids_output_dir):\n",
    "    \"\"\"\n",
    "    Convert ADNI data to BIDS format\n",
    "    \n",
    "    Parameters:\n",
    "    - adni_data_dir: Path to ADNI data (e.g., 'data/002_S_0295')\n",
    "    - bids_output_dir: Output BIDS directory (e.g., 'bids_dataset')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract subject ID from directory name (002_S_0295 -> 0020295)\n",
    "    subject_id = os.path.basename(adni_data_dir).replace('_', '').replace('S', '')\n",
    "    bids_subject_id = f\"sub-{subject_id}\"\n",
    "    \n",
    "    # Create BIDS directory structure\n",
    "    subject_dir = os.path.join(bids_output_dir, bids_subject_id)\n",
    "    anat_dir = os.path.join(subject_dir, 'anat')\n",
    "    pet_dir = os.path.join(subject_dir, 'pet')\n",
    "    \n",
    "    os.makedirs(anat_dir, exist_ok=True)\n",
    "    os.makedirs(pet_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Converting subject: {bids_subject_id}\")\n",
    "    print(f\"Output directory: {subject_dir}\")\n",
    "    \n",
    "    # 1. Convert MRI (T1w)\n",
    "    mri_pattern = os.path.join(adni_data_dir, 'MPR__GradWarp__B1_Correction__N3', '*', '*', '*.nii')\n",
    "    mri_files = glob.glob(mri_pattern)\n",
    "    \n",
    "    if mri_files:\n",
    "        mri_file = mri_files[0]  # Take the first match\n",
    "        output_t1w = os.path.join(anat_dir, f'{bids_subject_id}_T1w.nii.gz')\n",
    "        \n",
    "        # Load and save as compressed NIfTI\n",
    "        img = nib.load(mri_file)\n",
    "        nib.save(img, output_t1w)\n",
    "        print(f\"✓ Converted MRI: {os.path.basename(mri_file)} -> {os.path.basename(output_t1w)}\")\n",
    "    else:\n",
    "        print(\"✗ No MRI data found\")\n",
    "    \n",
    "    # 2. Convert AV45 PET\n",
    "    av45_pattern = os.path.join(adni_data_dir, 'AV45_Coreg,_Avg,_Standardized_Image_and_Voxel_Size', '*', '*', '*.dcm')\n",
    "    av45_files = glob.glob(av45_pattern)\n",
    "    \n",
    "    if av45_files:\n",
    "        output_av45 = os.path.join(pet_dir, f'{bids_subject_id}_trc-AV45_pet.nii.gz')\n",
    "        output_av45_json = os.path.join(pet_dir, f'{bids_subject_id}_trc-AV45_pet.json')\n",
    "        \n",
    "        # Convert DICOM series to NIfTI\n",
    "        convert_dicom_to_nifti(av45_files, output_av45)\n",
    "        \n",
    "        # Create JSON sidecar\n",
    "        pet_metadata = {\n",
    "            \"Manufacturer\": \"Siemens\",\n",
    "            \"TracerName\": \"AV45\",\n",
    "            \"TracerRadionuclide\": \"F18\",\n",
    "            \"InjectedRadioactivity\": 370,\n",
    "            \"InjectedRadioactivityUnits\": \"MBq\",\n",
    "            \"ModeOfAdministration\": \"bolus\"\n",
    "        }\n",
    "        with open(output_av45_json, 'w') as f:\n",
    "            json.dump(pet_metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"✓ Converted AV45 PET: {len(av45_files)} DICOM files -> {os.path.basename(output_av45)}\")\n",
    "    else:\n",
    "        print(\"✗ No AV45 PET data found\")\n",
    "    \n",
    "    # 3. Convert FDG PET\n",
    "    fdg_pattern = os.path.join(adni_data_dir, 'Coreg,_Avg,_Standardized_Image_and_Voxel_Size', '*', '*', '*.dcm')\n",
    "    fdg_files = glob.glob(fdg_pattern)\n",
    "    \n",
    "    if fdg_files:\n",
    "        output_fdg = os.path.join(pet_dir, f'{bids_subject_id}_trc-FDG_pet.nii.gz')\n",
    "        output_fdg_json = os.path.join(pet_dir, f'{bids_subject_id}_trc-FDG_pet.json')\n",
    "        \n",
    "        # Convert DICOM series to NIfTI\n",
    "        convert_dicom_to_nifti(fdg_files, output_fdg)\n",
    "        \n",
    "        # Create JSON sidecar\n",
    "        pet_metadata = {\n",
    "            \"Manufacturer\": \"Siemens\",\n",
    "            \"TracerName\": \"FDG\",\n",
    "            \"TracerRadionuclide\": \"F18\",\n",
    "            \"InjectedRadioactivity\": 370,\n",
    "            \"InjectedRadioactivityUnits\": \"MBq\",\n",
    "            \"ModeOfAdministration\": \"bolus\"\n",
    "        }\n",
    "        with open(output_fdg_json, 'w') as f:\n",
    "            json.dump(pet_metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"✓ Converted FDG PET: {len(fdg_files)} DICOM files -> {os.path.basename(output_fdg)}\")\n",
    "    else:\n",
    "        print(\"✗ No FDG PET data found\")\n",
    "    \n",
    "    return subject_dir\n",
    "\n",
    "\n",
    "def convert_dicom_to_nifti(dicom_files, output_path):\n",
    "    \"\"\"Convert DICOM series to NIfTI format\"\"\"\n",
    "    \n",
    "    # Import numpy here to ensure it's available\n",
    "    import numpy as np\n",
    "    \n",
    "    # Sort DICOM files by instance number\n",
    "    def get_instance_number(filepath):\n",
    "        try:\n",
    "            ds = pydicom.dcmread(filepath, stop_before_pixels=True)\n",
    "            return int(ds.InstanceNumber) if hasattr(ds, 'InstanceNumber') else 0\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    dicom_files_sorted = sorted(dicom_files, key=get_instance_number)\n",
    "    \n",
    "    # Read all slices and extract pixel data\n",
    "    pixel_arrays = []\n",
    "    \n",
    "    print(f\"  Reading {len(dicom_files_sorted)} DICOM slices...\")\n",
    "    \n",
    "    for idx, filepath in enumerate(dicom_files_sorted):\n",
    "        try:\n",
    "            # Read DICOM file\n",
    "            ds = pydicom.dcmread(filepath, force=True)\n",
    "            \n",
    "            # Get pixel array - this is where the error occurs\n",
    "            # We need to ensure numpy is available to pydicom\n",
    "            if hasattr(ds, 'pixel_array'):\n",
    "                pixel_data = ds.pixel_array\n",
    "                # Explicitly convert to numpy array\n",
    "                pixel_arrays.append(np.asarray(pixel_data, dtype=np.float32))\n",
    "            else:\n",
    "                print(f\"    Warning: No pixel data in {os.path.basename(filepath)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Error reading {os.path.basename(filepath)}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not pixel_arrays:\n",
    "        raise ValueError(\"No valid pixel data found in DICOM files\")\n",
    "    \n",
    "    # Stack all slices into 3D volume\n",
    "    img3d = np.stack(pixel_arrays, axis=-1)\n",
    "    print(f\"  Created 3D volume with shape: {img3d.shape}\")\n",
    "    \n",
    "    # Create NIfTI image (note: proper affine matrix should be calculated from DICOM headers)\n",
    "    # For simplicity, we use an identity matrix here\n",
    "    affine = np.eye(4)\n",
    "    nifti_img = nib.Nifti1Image(img3d, affine)\n",
    "    \n",
    "    # Save as compressed NIfTI\n",
    "    nib.save(nifti_img, output_path)\n",
    "    print(f\"  Saved to {output_path}\")\n",
    "\n",
    "\n",
    "def create_bids_metadata(bids_dir):\n",
    "    \"\"\"Create BIDS dataset_description.json and participants.tsv\"\"\"\n",
    "    \n",
    "    # Create dataset_description.json\n",
    "    dataset_desc = {\n",
    "        \"Name\": \"ADNI PET-MRI Dataset\",\n",
    "        \"BIDSVersion\": \"1.8.0\",\n",
    "        \"DatasetType\": \"raw\",\n",
    "        \"Authors\": [\"ADNI\"]\n",
    "    }\n",
    "    \n",
    "    desc_file = os.path.join(bids_dir, 'dataset_description.json')\n",
    "    with open(desc_file, 'w') as f:\n",
    "        json.dump(dataset_desc, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Created {desc_file}\")\n",
    "    \n",
    "    # Create participants.tsv\n",
    "    participants_file = os.path.join(bids_dir, 'participants.tsv')\n",
    "    with open(participants_file, 'w') as f:\n",
    "        f.write(\"participant_id\\tage\\tsex\\n\")\n",
    "        # Add participant info here (can be extracted from ADNI metadata)\n",
    "    \n",
    "    print(f\"✓ Created {participants_file}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"BIDS Conversion Script Ready!\")\n",
    "print(\"\\nTo convert your data, run:\")\n",
    "print(\"  convert_adni_to_bids('data/002_S_0295', 'bids_dataset')\")\n",
    "print(\"  create_bids_metadata('bids_dataset')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the conversion\n",
    "adni_data_path = 'data/002_S_0295'\n",
    "bids_output_path = 'bids_dataset'\n",
    "\n",
    "# Convert the ADNI data to BIDS format\n",
    "convert_adni_to_bids(adni_data_path, bids_output_path)\n",
    "\n",
    "# Create BIDS metadata files\n",
    "create_bids_metadata(bids_output_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BIDS Conversion Complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Preprocessing\n",
    "\n",
    "DeepPrep performs the following anatomical preprocessing steps:\n",
    "\n",
    "| Step | Process | What It Does |\n",
    "|------|---------|--------------|\n",
    "| **1** | **Motion Correction** | Align and average multiple T1w scans |\n",
    "| **2** | **Segmentation** (FastSurfer) | Divide brain into 95 regions |\n",
    "| **3** | **Skull Stripping** | Remove skull and non-brain tissue |\n",
    "| **4** | **Bias Correction** | Fix brightness inconsistencies |\n",
    "| **5** | **Surface Reconstruction** (FastCSR) | Build 3D cortical surface models |\n",
    "| **6** | **Spherical Projection** | Inflate surfaces to spheres |\n",
    "| **7** | **Surface Registration** (SUGAR) | Align to standard template |\n",
    "| **8** | **Parcellation** | Label brain regions by atlas |\n",
    "| **9** | **Volume Mapping** | Project surface labels to volume |\n",
    "| **10** | **Morphometry** | Extract cortical thickness, area, volume |\n",
    "\n",
    "### Which Steps Do You Need?\n",
    "\n",
    "Different research goals require different preprocessing steps:\n",
    "\n",
    "**Basic volumetric analysis** (brain volume, voxel-based morphometry):\n",
    "- Steps 1-4\n",
    "\n",
    "**ROI analysis** (hippocampus volume, subcortical structures):\n",
    "- Steps 1-4 (segmentation included)\n",
    "\n",
    "**Surface analysis** (cortical thickness, surface area):\n",
    "- Steps 1-7\n",
    "\n",
    "**Group comparison** (patients vs. controls):\n",
    "- Steps 1-8\n",
    "\n",
    "**Full analysis** (multimodal neuroimaging):\n",
    "- All steps 1-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DeepPrep Preprocessing\n",
    "#\n",
    "# OPTION 1: Use the provided shell script (Recommended)\n",
    "# In your terminal, run:\n",
    "#   ./run_deepprep.sh\n",
    "#\n",
    "# OPTION 2: Copy and paste the command below into your terminal\n",
    "\n",
    "import os\n",
    "bids_dir = os.path.abspath('bids_dataset')\n",
    "output_dir = os.path.abspath('deepprep_output')\n",
    "work_dir = os.path.abspath('deepprep_work')\n",
    "license_file = os.path.expanduser('~/freesurfer/license.txt')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"OPTION 1 (Recommended): Run the shell script\")\n",
    "print(\"=\"*70)\n",
    "print(\"./run_deepprep.sh\")\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"OPTION 2: Copy and run this command in your terminal:\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(f\"sudo docker run --gpus all --rm \\\\\")\n",
    "print(f\"    -v {bids_dir}:/bids:ro \\\\\")\n",
    "print(f\"    -v {output_dir}:/output \\\\\")\n",
    "print(f\"    -v {work_dir}:/work \\\\\")\n",
    "print(f\"    -v {license_file}:/opt/freesurfer/license.txt:ro \\\\\")\n",
    "print(f\"    pbfslab/deepprep:25.1.0 \\\\\")\n",
    "print(f\"    /bids /output participant \\\\\")\n",
    "print(f\"    --participant_label sub-0020295 \\\\\")\n",
    "print(f\"    --anat_only \\\\\")\n",
    "print(f\"    --skip_bids_validation \\\\\")\n",
    "print(f\"    --device auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize preprocessing results\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load images\n",
    "original = nib.load('bids_dataset/sub-0020295/anat/sub-0020295_T1w.nii.gz').get_fdata()\n",
    "skull_stripped = nib.load('deepprep_output/Recon/sub-0020295/mri/brainmask.mgz').get_fdata()\n",
    "bias_corrected = nib.load('deepprep_output/Recon/sub-0020295/mri/norm.mgz').get_fdata()\n",
    "\n",
    "# Show middle slice comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(original[:, :, original.shape[2]//2].T, cmap='gray', origin='lower')\n",
    "axes[0].set_title('Original T1w', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(skull_stripped[:, :, skull_stripped.shape[2]//2].T, cmap='gray', origin='lower')\n",
    "axes[1].set_title('Skull Stripped', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(bias_corrected[:, :, bias_corrected.shape[2]//2].T, cmap='gray', origin='lower')\n",
    "axes[2].set_title('Bias Corrected', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepprep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
