{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Brain Image Preprocessing Quick Start (Using DeepPrep)\n\n**DeepPrep**: Deep learning-powered brain image preprocessing (Nature Methods 2025)\n- 10× faster than fMRIPrep (~27 min vs 4-8 hours per subject)\n- Processes both T1 (structural) and fMRI (functional) data\n- Version: 25.1.0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install nibabel pandas numpy matplotlib seaborn tqdm scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your paths\n",
    "BIDS_DIR = '/path/to/bids_data'\n",
    "OUTPUT_DIR = '/path/to/output'\n",
    "FS_LICENSE = '/path/to/freesurfer_license.txt'\n",
    "DOCKER_IMAGE = 'pbfslab/deepprep:25.1.0'\n",
    "\n",
    "# Subject IDs to process\n",
    "SUBJECTS = ['001', '002', '003']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BIDS Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bids_structure(base_dir, subject_id, t1_file=None, fmri_file=None):\n",
    "    \"\"\"Create BIDS directory for a subject\"\"\"\n",
    "    import shutil\n",
    "    import json\n",
    "    \n",
    "    sub_dir = Path(base_dir) / f'sub-{subject_id}'\n",
    "    anat_dir = sub_dir / 'anat'\n",
    "    func_dir = sub_dir / 'func'\n",
    "    \n",
    "    anat_dir.mkdir(parents=True, exist_ok=True)\n",
    "    func_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if t1_file:\n",
    "        dest = anat_dir / f'sub-{subject_id}_T1w.nii.gz'\n",
    "        shutil.copy(t1_file, dest)\n",
    "        print(f\"✓ T1: {dest}\")\n",
    "    \n",
    "    if fmri_file:\n",
    "        dest = func_dir / f'sub-{subject_id}_task-rest_bold.nii.gz'\n",
    "        shutil.copy(fmri_file, dest)\n",
    "        print(f\"✓ fMRI: {dest}\")\n",
    "    \n",
    "    # Create dataset_description.json\n",
    "    desc_file = Path(base_dir) / 'dataset_description.json'\n",
    "    if not desc_file.exists():\n",
    "        with open(desc_file, 'w') as f:\n",
    "            json.dump({\"Name\": \"My Dataset\", \"BIDSVersion\": \"1.6.0\"}, f, indent=2)\n",
    "\n",
    "# Example usage\n",
    "# create_bids_structure(BIDS_DIR, '001', t1_file='/raw/t1.nii.gz', fmri_file='/raw/fmri.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DeepPrep Python Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPrepRunner:\n",
    "    def __init__(self, docker_image='pbfslab/deepprep:25.1.0', fs_license_path=None):\n",
    "        self.docker_image = docker_image\n",
    "        self.fs_license = Path(fs_license_path) if fs_license_path else None\n",
    "        \n",
    "        if self.fs_license and not self.fs_license.exists():\n",
    "            raise FileNotFoundError(f\"FreeSurfer license not found: {fs_license_path}\")\n",
    "    \n",
    "    def run(self, bids_dir, output_dir, participant_labels=None, anat_only=False, \n",
    "            nthreads=4, device='cpu', skip_bids_validation=False):\n",
    "        \"\"\"Run DeepPrep preprocessing\"\"\"\n",
    "        bids_dir = Path(bids_dir).resolve()\n",
    "        output_dir = Path(output_dir).resolve()\n",
    "        \n",
    "        cmd = [\n",
    "            'docker', 'run', '--rm', '-it',\n",
    "            '-v', f'{bids_dir}:/input:ro',\n",
    "            '-v', f'{output_dir}:/output',\n",
    "        ]\n",
    "        \n",
    "        if self.fs_license:\n",
    "            cmd.extend(['-v', f'{self.fs_license}:/license:ro'])\n",
    "        \n",
    "        if device == 'gpu':\n",
    "            cmd.extend(['--gpus', 'all'])\n",
    "        \n",
    "        cmd.append(self.docker_image)\n",
    "        cmd.extend(['/input', '/output', 'participant'])\n",
    "        \n",
    "        if self.fs_license:\n",
    "            cmd.extend(['--fs-license-file', '/license'])\n",
    "        \n",
    "        cmd.extend(['--nthreads', str(nthreads), '--device', device])\n",
    "        \n",
    "        if participant_labels:\n",
    "            cmd.extend(['--participant-label'] + participant_labels)\n",
    "        \n",
    "        if anat_only:\n",
    "            cmd.append('--anat-only')\n",
    "        \n",
    "        if skip_bids_validation:\n",
    "            cmd.append('--skip-bids-validation')\n",
    "        \n",
    "        print(f\"Running: {' '.join(cmd)}\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ Success!\")\n",
    "        else:\n",
    "            print(f\"✗ Error: {result.stderr}\")\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run DeepPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize runner\n",
    "runner = DeepPrepRunner(\n",
    "    docker_image=DOCKER_IMAGE,\n",
    "    fs_license_path=FS_LICENSE\n",
    ")\n",
    "\n",
    "# Process single subject\n",
    "result = runner.run(\n",
    "    bids_dir=BIDS_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    participant_labels=['001'],\n",
    "    nthreads=8,\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPrepLoader:\n",
    "    def __init__(self, output_dir, subject_id):\n",
    "        self.output_dir = Path(output_dir) / 'deepprep' / f'sub-{subject_id}'\n",
    "        self.subject_id = subject_id\n",
    "    \n",
    "    def load_t1(self, space='MNI152'):\n",
    "        \"\"\"Load preprocessed T1 image\"\"\"\n",
    "        path = self.output_dir / 'anat' / f'sub-{self.subject_id}_space-{space}_T1w.nii.gz'\n",
    "        img = nib.load(path)\n",
    "        return img.get_fdata(), img.affine\n",
    "    \n",
    "    def load_bold(self, task='rest', space='MNI152'):\n",
    "        \"\"\"Load preprocessed BOLD image\"\"\"\n",
    "        path = self.output_dir / 'func' / f'sub-{self.subject_id}_task-{task}_space-{space}_bold.nii.gz'\n",
    "        img = nib.load(path)\n",
    "        return img.get_fdata(), img.affine\n",
    "    \n",
    "    def load_confounds(self, task='rest'):\n",
    "        \"\"\"Load confounds for denoising\"\"\"\n",
    "        path = self.output_dir / 'func' / f'sub-{self.subject_id}_task-{task}_confounds.tsv'\n",
    "        return pd.read_csv(path, sep='\\t')\n",
    "    \n",
    "    def load_tissue_masks(self):\n",
    "        \"\"\"Load GM, WM, CSF probability maps\"\"\"\n",
    "        masks = {}\n",
    "        for tissue in ['GM', 'WM', 'CSF']:\n",
    "            path = self.output_dir / 'anat' / f'sub-{self.subject_id}_label-{tissue}_probseg.nii.gz'\n",
    "            masks[tissue] = nib.load(path).get_fdata()\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for subject 001\n",
    "loader = DeepPrepLoader(OUTPUT_DIR, '001')\n",
    "\n",
    "# Load T1\n",
    "t1_data, t1_affine = loader.load_t1()\n",
    "print(f\"T1 shape: {t1_data.shape}\")\n",
    "\n",
    "# Load fMRI\n",
    "bold_data, bold_affine = loader.load_bold()\n",
    "print(f\"BOLD shape: {bold_data.shape}\")\n",
    "\n",
    "# Load confounds\n",
    "confounds = loader.load_confounds()\n",
    "print(f\"Confounds: {confounds.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qc_metrics(output_dir, subject_id, task='rest'):\n",
    "    \"\"\"Extract QC metrics from confounds\"\"\"\n",
    "    loader = DeepPrepLoader(output_dir, subject_id)\n",
    "    confounds = loader.load_confounds(task)\n",
    "    \n",
    "    fd = confounds['framewise_displacement'].values\n",
    "    fd_mean = np.nanmean(fd)\n",
    "    fd_max = np.nanmax(fd)\n",
    "    \n",
    "    dvars_mean = np.nanmean(confounds['dvars'].values) if 'dvars' in confounds.columns else None\n",
    "    high_motion_tps = np.sum(fd > 0.5)\n",
    "    \n",
    "    return {\n",
    "        'subject_id': subject_id,\n",
    "        'fd_mean': fd_mean,\n",
    "        'fd_max': fd_max,\n",
    "        'dvars_mean': dvars_mean,\n",
    "        'high_motion_tps': high_motion_tps,\n",
    "        'total_tps': len(fd)\n",
    "    }\n",
    "\n",
    "# Run QC on all subjects\n",
    "qc_results = [extract_qc_metrics(OUTPUT_DIR, s) for s in SUBJECTS]\n",
    "qc_df = pd.DataFrame(qc_results)\n",
    "\n",
    "# Filter by quality (FD < 0.5 mm)\n",
    "good_subjects = qc_df[qc_df['fd_mean'] < 0.5]['subject_id'].tolist()\n",
    "print(f\"Subjects passing QC: {len(good_subjects)}/{len(SUBJECTS)}\")\n",
    "qc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize QC metrics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# FD distribution\n",
    "axes[0].hist(qc_df['fd_mean'], bins=20, edgecolor='black')\n",
    "axes[0].axvline(0.5, color='red', linestyle='--', label='Threshold')\n",
    "axes[0].set_xlabel('Mean FD (mm)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Head Motion Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# High-motion timepoints\n",
    "axes[1].bar(range(len(qc_df)), qc_df['high_motion_tps'])\n",
    "axes[1].set_xlabel('Subject Index')\n",
    "axes[1].set_ylabel('High-Motion Timepoints')\n",
    "axes[1].set_title('High-Motion TPs per Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Denoising fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def denoise_bold(bold_data, confounds, confound_columns):\n",
    "    \"\"\"Remove confounds from BOLD data\"\"\"\n",
    "    original_shape = bold_data.shape\n",
    "    bold_2d = bold_data.reshape(-1, original_shape[-1]).T  # (time, voxels)\n",
    "    \n",
    "    X = confounds[confound_columns].fillna(0).values\n",
    "    lr = LinearRegression()\n",
    "    denoised = np.zeros_like(bold_2d)\n",
    "    \n",
    "    for i in range(bold_2d.shape[1]):\n",
    "        y = bold_2d[:, i]\n",
    "        lr.fit(X, y)\n",
    "        denoised[:, i] = y - lr.predict(X)\n",
    "    \n",
    "    return denoised.T.reshape(original_shape)\n",
    "\n",
    "# Denoise\n",
    "confound_cols = ['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'csf', 'white_matter']\n",
    "clean_bold = denoise_bold(bold_data, confounds, confound_cols)\n",
    "\n",
    "print(f\"Original BOLD shape: {bold_data.shape}\")\n",
    "print(f\"Denoised BOLD shape: {clean_bold.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ROI Analysis & Functional Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi_timeseries(bold_data, atlas_data, roi_labels):\n",
    "    \"\"\"Extract mean timeseries for each ROI\"\"\"\n",
    "    n_timepoints = bold_data.shape[-1]\n",
    "    timeseries = np.zeros((len(roi_labels), n_timepoints))\n",
    "    \n",
    "    for i, label in enumerate(roi_labels):\n",
    "        mask = atlas_data == label\n",
    "        timeseries[i, :] = bold_data[mask].mean(axis=0)\n",
    "    \n",
    "    return timeseries\n",
    "\n",
    "def compute_connectivity(timeseries, method='correlation'):\n",
    "    \"\"\"Compute functional connectivity matrix\"\"\"\n",
    "    if method == 'correlation':\n",
    "        return np.corrcoef(timeseries)\n",
    "    elif method == 'partial_correlation':\n",
    "        from sklearn.covariance import LedoitWolf\n",
    "        estimator = LedoitWolf()\n",
    "        estimator.fit(timeseries.T)\n",
    "        precision = estimator.precision_\n",
    "        d = np.sqrt(np.diag(precision))\n",
    "        conn = -precision / np.outer(d, d)\n",
    "        np.fill_diagonal(conn, 1)\n",
    "        return conn\n",
    "\n",
    "# Example: Load atlas and compute connectivity\n",
    "# atlas_img = nib.load('atlas_MNI152.nii.gz')\n",
    "# atlas_data = atlas_img.get_fdata()\n",
    "# roi_ts = extract_roi_timeseries(clean_bold, atlas_data, range(1, 11))\n",
    "# conn_matrix = compute_connectivity(roi_ts, method='correlation')\n",
    "\n",
    "# # Visualize\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conn_matrix, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "# plt.title('Functional Connectivity Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. PyTorch Dataset for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, output_dir, subject_ids, modality='T1', space='MNI152', transform=None):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.subject_ids = subject_ids\n",
    "        self.modality = modality\n",
    "        self.space = space\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.subject_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        subj_id = self.subject_ids[idx]\n",
    "        loader = DeepPrepLoader(self.output_dir, subj_id)\n",
    "        \n",
    "        if self.modality == 'T1':\n",
    "            data, _ = loader.load_t1(space=self.space)\n",
    "        elif self.modality == 'BOLD':\n",
    "            data, _ = loader.load_bold(space=self.space)\n",
    "            data = np.mean(data, axis=-1)  # Average over time\n",
    "        \n",
    "        data = torch.FloatTensor(data).unsqueeze(0)  # Add channel dim\n",
    "        data = (data - data.mean()) / (data.std() + 1e-8)  # Normalize\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data, subj_id\n",
    "\n",
    "# Create dataset\n",
    "dataset = BrainMRIDataset(OUTPUT_DIR, good_subjects, modality='T1')\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "# Test\n",
    "for batch_data, batch_ids in dataloader:\n",
    "    print(f\"Batch shape: {batch_data.shape}\")\n",
    "    print(f\"Batch IDs: {batch_ids}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Complete Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_load(subject_ids, bids_dir, output_dir, fs_license, \n",
    "                       fd_threshold=0.5, nthreads=4):\n",
    "    \"\"\"\n",
    "    Complete workflow: preprocess → QC → load data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Preprocessed data and QC metrics for passing subjects\n",
    "    \"\"\"\n",
    "    # 1. Run DeepPrep\n",
    "    print(\"Step 1: Running DeepPrep...\")\n",
    "    runner = DeepPrepRunner(fs_license_path=fs_license)\n",
    "    \n",
    "    for subj in subject_ids:\n",
    "        result = runner.run(\n",
    "            bids_dir=bids_dir,\n",
    "            output_dir=output_dir,\n",
    "            participant_labels=[subj],\n",
    "            nthreads=nthreads\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            print(f\"✗ Failed: {subj}\")\n",
    "    \n",
    "    # 2. Quality control\n",
    "    print(\"\\nStep 2: Quality control...\")\n",
    "    qc_results = []\n",
    "    for subj in subject_ids:\n",
    "        try:\n",
    "            metrics = extract_qc_metrics(output_dir, subj)\n",
    "            qc_results.append(metrics)\n",
    "        except Exception as e:\n",
    "            print(f\"QC failed for {subj}: {e}\")\n",
    "    \n",
    "    qc_df = pd.DataFrame(qc_results)\n",
    "    passing = qc_df[qc_df['fd_mean'] < fd_threshold]['subject_id'].tolist()\n",
    "    print(f\"QC passed: {len(passing)}/{len(subject_ids)}\")\n",
    "    \n",
    "    # 3. Load data\n",
    "    print(\"\\nStep 3: Loading preprocessed data...\")\n",
    "    dataset = {}\n",
    "    \n",
    "    for subj in passing:\n",
    "        try:\n",
    "            loader = DeepPrepLoader(output_dir, subj)\n",
    "            t1_data, affine = loader.load_t1()\n",
    "            \n",
    "            dataset[subj] = {\n",
    "                'data': t1_data,\n",
    "                'affine': affine,\n",
    "                'qc': qc_df[qc_df['subject_id'] == subj].to_dict('records')[0]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {subj}: {e}\")\n",
    "    \n",
    "    print(f\"\\nLoaded {len(dataset)} subjects\")\n",
    "    return dataset, qc_df\n",
    "\n",
    "# Usage\n",
    "# dataset, qc_df = preprocess_and_load(\n",
    "#     subject_ids=['001', '002', '003'],\n",
    "#     bids_dir=BIDS_DIR,\n",
    "#     output_dir=OUTPUT_DIR,\n",
    "#     fs_license=FS_LICENSE,\n",
    "#     fd_threshold=0.5,\n",
    "#     nthreads=8\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- **Docs**: https://deepprep.readthedocs.io\n",
    "- **GitHub**: https://github.com/pBFSLab/DeepPrep\n",
    "- **Paper**: Nature Methods (2025) - https://www.nature.com/articles/s41592-025-02599-1\n",
    "- **FreeSurfer License**: https://surfer.nmr.mgh.harvard.edu/registration.html (free)\n",
    "\n",
    "**Learning**:\n",
    "- BIDS: https://bids-specification.readthedocs.io\n",
    "- Nilearn: https://nilearn.github.io\n",
    "- MONAI: https://monai.io"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}