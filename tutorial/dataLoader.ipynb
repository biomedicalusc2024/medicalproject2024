{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DataLoader Parameters\n",
    "### DataLoader\n",
    "The `DataLoader` class is a versatile tool for loading various medical datasets. It allows users to specify the dataset name, dataset split and other parameters to customize the data loading process. \n",
    "#### Key Parameters:\n",
    "- **name**: The name of the dataset to load, sometimes subset is needed (e.g., \"MEPS\", \"NHIS\", \"StrokePrediction\", \"MedMnist-nodulemnist3d\").\n",
    "- **task**: The specific task or subset of the dataset to load (e.g., task=10 for MEPS).\n",
    "- **variables**: The specific variables of dataset to load.\n",
    "\n",
    "### get_data\n",
    "The `get_data()` method is used to retrieve the data in the desired format and split. It provides flexibility to handle different datasets and tasks efficiently.\n",
    "#### Key Parameters:\n",
    "- **format**: The format in which the data is returned (e.g., 'df' for pandas DataFrame, 'DeepPurpose' for deep learning purposes).\n",
    "- **dataset**: The data split to load (e.g., 'train', 'test', 'validation', 'all'), different dataset may support different split.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Installation\n",
    "Import required packages and setup environment variables for the medical project dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path added to sys.path: /home/tjl20001104/workspace/Projects/USC/biobank/hugging-health\n",
      "Environment setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project directory to the Python path\n",
    "notebook_path = os.getcwd()  # Get the current working directory\n",
    "project_path = os.path.abspath(os.path.join(notebook_path, \"../..\"))\n",
    "sys.path.append(project_path)\n",
    "\n",
    "# Verify the setup\n",
    "print(f\"Project path added to sys.path: {project_path}\")\n",
    "print(\"Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader Class Overview\n",
    "We support different tasks such as classification, detection, NER, QA, segmentation, etc. Please refer to README for full coverage.\n",
    "\n",
    "Here is an introduction to the DataLoader class structure and its main components from medicalproject2024.dataLoader.classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid dataset names:\n",
      "MedMnist-adrenalmnist3d\n",
      "MedMnist-adrenalmnist3d_64\n",
      "MedMnist-bloodmnist\n",
      "MedMnist-bloodmnist_128\n",
      "MedMnist-bloodmnist_224\n",
      "MedMnist-bloodmnist_64\n",
      "MedMnist-breastmnist\n",
      "MedMnist-breastmnist_128\n",
      "MedMnist-breastmnist_224\n",
      "MedMnist-breastmnist_64\n",
      "MedMnist-chestmnist\n",
      "MedMnist-chestmnist_128\n",
      "MedMnist-chestmnist_224\n",
      "MedMnist-chestmnist_64\n",
      "MedMnist-dermamnist\n",
      "MedMnist-dermamnist_128\n",
      "MedMnist-dermamnist_224\n",
      "MedMnist-dermamnist_64\n",
      "MedMnist-fracturemnist3d\n",
      "MedMnist-fracturemnist3d_64\n",
      "MedMnist-nodulemnist3d\n",
      "MedMnist-nodulemnist3d_64\n",
      "MedMnist-octmnist\n",
      "MedMnist-octmnist_128\n",
      "MedMnist-octmnist_224\n",
      "MedMnist-octmnist_64\n",
      "MedMnist-organamnist\n",
      "MedMnist-organamnist_128\n",
      "MedMnist-organamnist_224\n",
      "MedMnist-organamnist_64\n",
      "MedMnist-organcmnist\n",
      "MedMnist-organcmnist_128\n",
      "MedMnist-organcmnist_224\n",
      "MedMnist-organcmnist_64\n",
      "MedMnist-organmnist3d\n",
      "MedMnist-organmnist3d_64\n",
      "MedMnist-organsmnist\n",
      "MedMnist-organsmnist_128\n",
      "MedMnist-organsmnist_224\n",
      "MedMnist-organsmnist_64\n",
      "MedMnist-pathmnist\n",
      "MedMnist-pathmnist_128\n",
      "MedMnist-pathmnist_224\n",
      "MedMnist-pathmnist_64\n",
      "MedMnist-pneumoniamnist\n",
      "MedMnist-pneumoniamnist_128\n",
      "MedMnist-pneumoniamnist_224\n",
      "MedMnist-pneumoniamnist_64\n",
      "MedMnist-retinamnist\n",
      "MedMnist-retinamnist_128\n",
      "MedMnist-retinamnist_224\n",
      "MedMnist-retinamnist_64\n",
      "MedMnist-synapsemnist3d\n",
      "MedMnist-synapsemnist3d_64\n",
      "MedMnist-tissuemnist\n",
      "MedMnist-tissuemnist_128\n",
      "MedMnist-tissuemnist_224\n",
      "MedMnist-tissuemnist_64\n",
      "MedMnist-vesselmnist3d\n",
      "MedMnist-vesselmnist3d_64\n",
      "IS_A-hard\n",
      "IS_A-easy\n",
      "ROND\n",
      "ChestXRays\n",
      "CheXpert_small\n",
      "Cirrhosis\n",
      "HeartFailurePrediction\n",
      "HepatitisCPrediction\n",
      "PTB_XL\n",
      "HoC\n",
      "StrokePrediction\n",
      "NHIS\n",
      "MEPS\n"
     ]
    }
   ],
   "source": [
    "# Import the DataLoader class from the classification module\n",
    "from medicalproject2024.dataLoader.classification import DataLoader, SUPPORTED_DATASETS\n",
    "\n",
    "# Display the structure and main components of the DataLoader class, check valid dataset names\n",
    "print(\"Valid dataset names:\")\n",
    "print(\"\\n\".join(SUPPORTED_DATASETS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Classification Data\n",
    "Demonstrate how to load different classification datasets (e.g., MEPS, NHIS) using the DataLoader class with specific task parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local default dataset...\n",
      "Loading data from default dataset for task Predict Hypertension Diagnosis Age\n",
      "Found local default dataset...\n",
      "Loading data from default dataset for task Classify individuals based on their combined health and mental well-being\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the MEPS dataset:\n",
      "   PHQ2  AGE  SEX  MARSTAT  K6SUM\n",
      "0   0.0   39    1       10      2\n",
      "1   0.0   40    2       10      2\n",
      "2   4.0   52    1       40     98\n",
      "3   1.0   22    1       50      5\n",
      "4   0.0   19    1       50      0\n",
      "\n",
      "First few rows of the NHIS dataset:\n",
      "   HEALTH  WORFREQ  DEPFREQ  AGE  SEX  EDUC  BMICAT  SMOKEV\n",
      "0       2        0        0   41    2   114       9       0\n",
      "1       3        0        0   67    1   301       9       0\n",
      "2       2        0        0   62    1   999       2       1\n",
      "3       2        0        0   64    2   301       9       0\n",
      "4       1        0        0   25    1   301       9       0\n"
     ]
    }
   ],
   "source": [
    "# Create a DataLoader instance for the MEPS dataset with a specific task\n",
    "meps_dataloader = DataLoader(name=\"MEPS\", task=10)\n",
    "# Load the data as a DataFrame\n",
    "meps_data = meps_dataloader.get_data(format=\"df\")\n",
    "# Display the first few rows of the loaded MEPS dataset\n",
    "print(\"First few rows of the MEPS dataset:\")\n",
    "print(meps_data.head())\n",
    "\n",
    "\n",
    "# Create a DataLoader instance for the NHIS dataset with a specific task\n",
    "nhis_dataloader = DataLoader(name=\"NHIS\", task=5)\n",
    "# Load the data as a DataFrame\n",
    "nhis_data = nhis_dataloader.get_data(format=\"df\")\n",
    "# Display the first few rows of the loaded NHIS dataset\n",
    "print(\"\\nFirst few rows of the NHIS dataset:\")\n",
    "print(nhis_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Different Datasets\n",
    "Examples of loading various medical datasets like ChestXRays, CheXpert_small, and other supported datasets mentioned in the project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Found local copy...\n",
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the StrokePrediction dataset:\n",
      "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0   9046    Male  67.0             0              1          Yes   \n",
      "1  51676  Female  61.0             0              0          Yes   \n",
      "2  31112    Male  80.0             0              1          Yes   \n",
      "3  60182  Female  49.0             0              0          Yes   \n",
      "4   1665  Female  79.0             1              0          Yes   \n",
      "\n",
      "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
      "0        Private          Urban             228.69  36.6  formerly smoked   \n",
      "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
      "2        Private          Rural             105.92  32.5     never smoked   \n",
      "3        Private          Urban             171.23  34.4           smokes   \n",
      "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
      "\n",
      "   stroke  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "\n",
      "First few rows of the ROND dataset:\n",
      "                                                data           label\n",
      "0  Head and neck cancers of tumors located at the...  Proton therapy\n",
      "1  Lung cancers in the middle of chest or near th...  Proton therapy\n",
      "2            Lower-cost option for prostate cancers.  Photon therapy\n",
      "3                               Cancers in children.  Proton therapy\n",
      "4                   Less sensitive to uncertainties.  Photon therapy\n",
      "\n",
      "First few rows of the MedMnist dataset, nodulemnist3d subset:\n",
      "                                               image label\n",
      "0  [[[38, 37, 24, 32, 56, 132, 169, 186, 205, 191...   [0]\n",
      "1  [[[193, 188, 184, 157, 180, 194, 195, 184, 69,...   [1]\n",
      "2  [[[167, 166, 168, 178, 170, 192, 191, 190, 185...   [1]\n",
      "3  [[[193, 173, 170, 191, 198, 199, 197, 198, 200...   [0]\n",
      "4  [[[10, 11, 12, 11, 40, 108, 62, 21, 12, 10, 11...   [0]\n"
     ]
    }
   ],
   "source": [
    "# Load and display data for the StrokePrediction dataset\n",
    "stroke_dataloader = DataLoader(name=\"StrokePrediction\")\n",
    "stroke_data = stroke_dataloader.get_data(format=\"df\")\n",
    "print(\"\\nFirst few rows of the StrokePrediction dataset:\")\n",
    "print(stroke_data.head())\n",
    "\n",
    "# Load and display data for the ROND dataset\n",
    "rond_dataloader = DataLoader(name=\"ROND\")\n",
    "rond_data = rond_dataloader.get_data(format=\"df\")\n",
    "print(\"\\nFirst few rows of the ROND dataset:\")\n",
    "print(rond_data.head())\n",
    "\n",
    "# Load and display data for the ROND dataset\n",
    "MedMnist_dataloader = DataLoader(name=\"MedMnist-nodulemnist3d\")\n",
    "MedMnist_data = MedMnist_dataloader.get_data(format=\"df\")\n",
    "print(\"\\nFirst few rows of the MedMnist dataset, nodulemnist3d subset:\")\n",
    "print(MedMnist_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Format Conversions\n",
    "Show how to use the get_data() method with different format parameters (e.g., 'df' for pandas DataFrame) and handle the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEPS dataset loaded as a pandas DataFrame:\n",
      "   PHQ2  AGE  SEX  MARSTAT  K6SUM\n",
      "0   0.0   39    1       10      2\n",
      "1   0.0   40    2       10      2\n",
      "2   4.0   52    1       40     98\n",
      "3   1.0   22    1       50      5\n",
      "4   0.0   19    1       50      0\n",
      "\n",
      "MEPS dataset loaded for deep learning purpose:\n",
      "[{'PHQ2': 0.0, 'AGE': 39, 'SEX': 1, 'MARSTAT': 10, 'K6SUM': 2}, {'PHQ2': 0.0, 'AGE': 40, 'SEX': 2, 'MARSTAT': 10, 'K6SUM': 2}, {'PHQ2': 4.0, 'AGE': 52, 'SEX': 1, 'MARSTAT': 40, 'K6SUM': 98}, {'PHQ2': 1.0, 'AGE': 22, 'SEX': 1, 'MARSTAT': 50, 'K6SUM': 5}, {'PHQ2': 0.0, 'AGE': 19, 'SEX': 1, 'MARSTAT': 50, 'K6SUM': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the use of `get_data()` method with different format parameters\n",
    "\n",
    "# Load the MEPS dataset as a pandas DataFrame\n",
    "meps_data_df = meps_dataloader.get_data(format=\"df\")\n",
    "print(\"MEPS dataset loaded as a pandas DataFrame:\")\n",
    "print(meps_data_df.head())\n",
    "\n",
    "# Load the MEPS dataset as a NumPy array\n",
    "meps_data_np = meps_dataloader.get_data(format=\"DeepPurpose\")\n",
    "print(\"\\nMEPS dataset loaded for deep learning purpose:\")\n",
    "print(meps_data_np[:5])  # Display the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Different Data Split\n",
    "Explain how to specify different dataset parameters and their effects on the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the train split of the MedMnist dataset, nodulemnist3d subset:\n",
      "                                               image label\n",
      "0  [[[38, 37, 24, 32, 56, 132, 169, 186, 205, 191...   [0]\n",
      "1  [[[193, 188, 184, 157, 180, 194, 195, 184, 69,...   [1]\n",
      "2  [[[167, 166, 168, 178, 170, 192, 191, 190, 185...   [1]\n",
      "3  [[[193, 173, 170, 191, 198, 199, 197, 198, 200...   [0]\n",
      "4  [[[10, 11, 12, 11, 40, 108, 62, 21, 12, 10, 11...   [0]\n",
      "\n",
      "First few rows of the test split of the MedMnist dataset, nodulemnist3d subset:\n",
      "                                               image label\n",
      "0  [[[21, 28, 19, 16, 16, 21, 21, 24, 33, 31, 29,...   [0]\n",
      "1  [[[19, 18, 25, 18, 21, 19, 19, 19, 18, 16, 17,...   [0]\n",
      "2  [[[164, 164, 163, 166, 164, 164, 164, 162, 160...   [0]\n",
      "3  [[[162, 162, 162, 162, 165, 165, 162, 164, 163...   [0]\n",
      "4  [[[26, 26, 26, 24, 23, 25, 30, 34, 36, 37, 39,...   [0]\n",
      "\n",
      "First few rows of the validation split of the MedMnist dataset, nodulemnist3d subset:\n",
      "                                               image label\n",
      "0  [[[25, 28, 21, 20, 18, 16, 21, 23, 28, 25, 24,...   [1]\n",
      "1  [[[189, 150, 191, 173, 163, 173, 149, 166, 154...   [0]\n",
      "2  [[[10, 10, 3, 11, 15, 21, 13, 14, 26, 53, 49, ...   [0]\n",
      "3  [[[14, 22, 26, 21, 11, 10, 13, 19, 41, 46, 36,...   [0]\n",
      "4  [[[26, 23, 44, 62, 21, 17, 28, 28, 16, 11, 15,...   [1]\n",
      "\n",
      "First few rows of the whole MedMnist dataset, nodulemnist3d subset:\n",
      "                                               image label\n",
      "0  [[[38, 37, 24, 32, 56, 132, 169, 186, 205, 191...   [0]\n",
      "1  [[[193, 188, 184, 157, 180, 194, 195, 184, 69,...   [1]\n",
      "2  [[[167, 166, 168, 178, 170, 192, 191, 190, 185...   [1]\n",
      "3  [[[193, 173, 170, 191, 198, 199, 197, 198, 200...   [0]\n",
      "4  [[[10, 11, 12, 11, 40, 108, 62, 21, 12, 10, 11...   [0]\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate handling different tasks with dataset split \"train\", \"test\", \"validation\", \"all\"\n",
    "MedMnist_data = MedMnist_dataloader.get_data(format=\"df\", dataset='train')\n",
    "print(\"\\nFirst few rows of the train split of the MedMnist dataset, nodulemnist3d subset:\")\n",
    "print(MedMnist_data.head())\n",
    "\n",
    "MedMnist_data = MedMnist_dataloader.get_data(format=\"df\", dataset='test')\n",
    "print(\"\\nFirst few rows of the test split of the MedMnist dataset, nodulemnist3d subset:\")\n",
    "print(MedMnist_data.head())\n",
    "\n",
    "MedMnist_data = MedMnist_dataloader.get_data(format=\"df\", dataset='validation')\n",
    "print(\"\\nFirst few rows of the validation split of the MedMnist dataset, nodulemnist3d subset:\")\n",
    "print(MedMnist_data.head())\n",
    "\n",
    "MedMnist_data = MedMnist_dataloader.get_data(format=\"df\", dataset='all')\n",
    "print(\"\\nFirst few rows of the whole MedMnist dataset, nodulemnist3d subset:\")\n",
    "print(MedMnist_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging-health",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
